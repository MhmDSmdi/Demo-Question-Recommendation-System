{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MhmDSmdi/Text-Similarity/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW2qVsE8ewL0",
        "colab_type": "text"
      },
      "source": [
        "In this project we need to find similarity between persian sentences which are in concept of ophthalmology. First we must load fasttext pre-trained model for persian language an un-zip it with following scripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNsvGCd8jDZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -q hazm\n",
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
        "# !gunzip cc.fa.300.bin.gz\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-cEry6ahjTd",
        "colab_type": "text"
      },
      "source": [
        "After that, we have to load our opthalmology data set form google drive in order to tune general pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTivJ50OpEI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgA7-FFOh_Np",
        "colab_type": "text"
      },
      "source": [
        "First step in natural language processing is data pre-processing which cleans our data by normalizing, stemming or lemmatizing. the most important step in data cleaning is removing stop-words from our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLoWPY4jiu9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "from hazm import Normalizer, Stemmer, Lemmatizer, sent_tokenize, word_tokenize, stopwords_list\n",
        "\n",
        "stops = set(stopwords_list())\n",
        "\n",
        "\n",
        "def load_dataset(file_name, column_name='question'):\n",
        "    data = pickle.load(open(file_name, \"rb\"))\n",
        "    statements = []\n",
        "    for i in range(len(data)):\n",
        "        statements.append(data[i][column_name])\n",
        "    return statements\n",
        "\n",
        "\n",
        "def statement_pre_processing(input_statement):\n",
        "    normalizer = Normalizer()\n",
        "    lemmatizer = Lemmatizer()\n",
        "    input_statement = normalizer.normalize(input_statement)\n",
        "    input_statement = [lemmatizer.lemmatize(word) for word in word_tokenize(input_statement) if word not in stops]\n",
        "    return input_statement\n",
        "\n",
        "\n",
        "def dataset_cleaner(dataset):\n",
        "    statements = []\n",
        "    normalizer = Normalizer()\n",
        "    lemmatizer = Lemmatizer()\n",
        "    for i in range(len(dataset)):\n",
        "        normalized_statement = normalizer.normalize(dataset[i])\n",
        "        # for sentence in sent_tokenize(dataset[i]):\n",
        "        word_list = [lemmatizer.lemmatize(word) for word in word_tokenize(normalized_statement) if word not in stops]\n",
        "        statements.append(word_list)\n",
        "    return statements\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx-2Jy42hlbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "import gensim\n",
        "\n",
        "from gensim.models import Phrases, Word2Vec, FastText\n",
        "from gensim.models.phrases import Phraser\n",
        "from gensim.similarities import WmdSimilarity\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "\n",
        "def load_pre_trained_model(file_name, encoding='utf-8'):\n",
        "    # model = gensim.models.KeyedVectors.load_word2vec_format(file_name)\n",
        "    model = FastText.load_fasttext_format(file_name)\n",
        "    # model.save('fasttext_fa_model')\n",
        "    return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqMWYDMKhnkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_word2vec_bigram(word_statements, name='word2vec_fa_model'):\n",
        "    phrases = Phrases(word_statements, min_count=30, progress_per=10000)\n",
        "    bigram = Phraser(phrases)\n",
        "    sentences = bigram[word_statements]\n",
        "    num_cores = multiprocessing.cpu_count()\n",
        "    w2v_model = Word2Vec(min_count=20,\n",
        "                         window=2,\n",
        "                         size=300,\n",
        "                         sample=6e-5,\n",
        "                         alpha=0.03,\n",
        "                         min_alpha=0.0007,\n",
        "                         negative=20,\n",
        "                         workers=num_cores - 1)\n",
        "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
        "    w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
        "    w2v_model.save(name)\n",
        "    w2v_model.init_sims(replace=True)\n",
        "    return w2v_model\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ91mPp_hvk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def progbar(curr, full_progbar):\n",
        "    frac = curr / full_progbar\n",
        "    filled_progbar = round(frac * full_progbar)\n",
        "    print('\\r', '#' * filled_progbar + '-' * (full_progbar - filled_progbar), '[{:>7.2%}]'.format(frac), end='')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgU4CFahopBk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARRCbb83hyVX",
        "colab_type": "code",
        "outputId": "127e0714-4b57-4783-eeca-d92985c803db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "progbar(0, 100)\n",
        "medical_questions = load_dataset(\"./drive/My Drive/Colab Notebooks/data_all.pickle\")\n",
        "medical_questions_words = dataset_cleaner(medical_questions)\n",
        "progbar(45, 100)\n",
        "model = load_pre_trained_model('./cc.fa.300.bin')\n",
        "progbar(65, 100)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " #############################################------------------------------------------------------- [ 45.00%]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r #################################################################----------------------------------- [ 65.00%]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaTjplEIowh9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWhksMt7ox7N",
        "colab_type": "text"
      },
      "source": [
        "Until now, we have loaded fasttext's pre-traines model and our ophthalmology dataset. As I saied above, for get more accurate result, we should train fasttext pre-trained model again because, fasttext model is very general and we need to tune it for ophthalmology and medical field.\n",
        "After train fasttext model, we should use word mover distance (WMD) to find similarity between user's query and our medical corpus.\n",
        "\n",
        "**For this you need to gensim 3.7 or higher so if your gensim lib. is lower, you need to update it with following script :**\n",
        "\n",
        "```\n",
        "!pip install gensim==3.8 [or higher]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4MyQZg7h2Dz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d48b06a-540f-4d6e-e7cf-d403b85aabb6"
      },
      "source": [
        "model.build_vocab(medical_questions_words, update=True)\n",
        "model.train(medical_questions_words, total_examples=len(medical_questions_words), epochs=model.epochs)\n",
        "progbar(70, 100)\n",
        "instance = WmdSimilarity(medical_questions_words, model, num_best=10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r ######################################################################------------------------------ [ 70.00%]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDTSQbBQFAhG",
        "colab_type": "text"
      },
      "source": [
        "Finally we just need to input a sentence and get output which is the mose similar sentences and its score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlPFvAyXh4V_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "f8be5118-13e8-442c-d5cc-5258cae9bf47"
      },
      "source": [
        "user_question = ['آیا برای عمل لیزیک باید ناشتا بود؟',\n",
        "                 'برای عمل لیزیک نباید سیگار کشید؟',\n",
        "                 'سلام خسته نباشید چشمم درد میکنه خواستم بدونم باید چیکار کنم؟',\n",
        "                 'فوتبال ورزش پر هیجانی است']\n",
        "\n",
        "for i in range(len(user_question)):\n",
        "    query = statement_pre_processing(user_question[i])\n",
        "    sims = instance[query]\n",
        "    print('Query: ' + user_question[i])\n",
        "    for j in range(10):\n",
        "        print(medical_questions[sims[j][0]] + \"(\"+'sim = %.4f' % sims[j][1]+\")\")\n",
        "    print()\n",
        "    progbar(i * 5 + 75, 100)\n",
        "progbar(100, 100)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: آیا برای عمل لیزیک باید ناشتا بود؟\n",
            "آیا برای عمل لیزیک باید ناشتا بود؟(sim = 1.0000)\n",
            "آیا انجام پیریمتری قبل از لیزیک لازم است؟(sim = 0.7721)\n",
            "هزينه عمل ليزيك چند است؟(sim = 0.7717)\n",
            "با سلام. آیا امکان عمل لیزیک برای همه افراد وجود دارد؟(sim = 0.7445)\n",
            "انجام عمل لیزیک چه شرایطی دارد؟(sim = 0.7435)\n",
            "آيا با داشتن آستيكمات بالا ميتوان عمل ليزيك انجام داد؟(sim = 0.7287)\n",
            "با سلام. درد عمل لیزیک به چه علت است؟(sim = 0.7258)\n",
            "با سلاماگر ممكن است بفرماييد كه عمل ليزيك بهتر است يا prk ؟(sim = 0.7218)\n",
            "ايا با وجود استيگمات بودن چشم امكان عمل ليزيك وجود دارد؟(sim = 0.7200)\n",
            "عمل فمتو لیزیک  چیست؟(sim = 0.7176)\n",
            "\n",
            " ###########################################################################------------------------- [ 75.00%]Query: برای عمل لیزیک نباید سیگار کشید؟\n",
            "آیا کشیدن سیگار بعد از عمل لیزیک منعی دارد؟(sim = 0.7998)\n",
            "انجام عمل لیزیک چه شرایطی دارد؟(sim = 0.7969)\n",
            "با سلام. آیا امکان عمل لیزیک برای همه افراد وجود دارد؟(sim = 0.7943)\n",
            "هزينه عمل ليزيك چند است؟(sim = 0.7845)\n",
            "آيا با داشتن آستيكمات بالا ميتوان عمل ليزيك انجام داد؟(sim = 0.7788)\n",
            "با سلام. درد عمل لیزیک به چه علت است؟(sim = 0.7682)\n",
            "با سلاماگر ممكن است بفرماييد كه عمل ليزيك بهتر است يا prk ؟(sim = 0.7658)\n",
            "ايا با وجود استيگمات بودن چشم امكان عمل ليزيك وجود دارد؟(sim = 0.7654)\n",
            "با سلام. چه کسانی می توانند تحت عمل لیزیک قرار گیرند؟(sim = 0.7621)\n",
            "آیا انجام پیریمتری قبل از لیزیک لازم است؟(sim = 0.7502)\n",
            "\n",
            " ################################################################################-------------------- [ 80.00%]Query: سلام خسته نباشید چشمم درد میکنه خواستم بدونم باید چیکار کنم؟\n",
            "با سلام می خواستم بپرسم برای انحراف چشم هم عملی هست که این انحراف از بین برود؟(sim = 0.8201)\n",
            "با سلام و خسته نباشید آیا میتوان با جراحی رنگ چشم را تغییر داد؟(sim = 0.8153)\n",
            "سلام خسته نباشید میخواستم بدونم نمره چشم برای یک چشم باید 7دیوپتر باشد یا برای هر دو چشم  برای عمل لیزیک ؟با تشکر.(sim = 0.8096)\n",
            "سلام خسته نباشید تغییر رنگ چشم با لیزر کدام دکتر تو ایران انجام میده؟(sim = 0.8081)\n",
            "با سلام. میخواستم بدونم تنبلی چشم با عمل یا لیزر درمان نمیشود ؟(sim = 0.8027)\n",
            "سلام.ميخواستم بدونم ايا هزينه عمل دوتا چشم يكي است يا نه؟(sim = 0.7980)\n",
            "با سلام میخواستم بدونم برای درمان سرخی چشم در تابستون چیکار کنیم ؟(sim = 0.7977)\n",
            "باسلام.من انحراف مخفی چشم دارم خواستم بدونم درمان داره یا نه؟(sim = 0.7976)\n",
            "با سلام. درد عمل لیزیک به چه علت است؟(sim = 0.7911)\n",
            "سلام خسته نباشید.آیادرد چشم سه ماه بعدازعمل لازک عادی است؟(sim = 0.7896)\n",
            "\n",
            " #####################################################################################--------------- [ 85.00%]Query: فوتبال ورزش پر هیجانی است\n",
            "با سلام. آیا باید از انجام ورزش بعد از عمل لیزیک خودداری کرد؟؟(sim = 0.5772)\n",
            "سلام ميخواستم بدونم بعد از عمل ميشه ورزش هاي فيتنس انجام داد و ورزش هاي پر تحرك و پر فشار؟اگر نه كه تا چه مدت بايد صبر كرد؟(sim = 0.5740)\n",
            "چند روز بعد از لازک می توان با خیال راحت فوتبال بازی کرد ؟(sim = 0.5739)\n",
            "آیا بیماریcnv قابل درمان هست؟؟(sim = 0.5716)\n",
            "سلام خدمت خانم دكتر فرحيلطفا در مورد درمان انحراف چشم با استفاده از ورزش و قطره چشمي بيشتر توضيح دهيد . روش ورزش دادن به چشم چگونه مي باشد. نوع قطره چشمي كه براي درمان استفاده مي شود چيست ؟(sim = 0.5688)\n",
            "بعد از عمل کاشت حلقه چه مدت باید طول بکشد تا ورزش بدن سازی انجام داد؟(sim = 0.5686)\n",
            "بيماري چشميtorchاطلاعات مي خواستم(sim = 0.5677)\n",
            "سلام چه مدت پس از عمل پیوند میتوان ورزش دوچرخه ثابت-کوه نوردی و بدنسازی سبک انجام داد؟؟(sim = 0.5655)\n",
            "شبكيه چشمهاي من از گوشه هايش نازكست آيامن ميتوانم فوتبال بازي كنم(sim = 0.5653)\n",
            "انجام ورزش ايروبيك چه مدت بعد از عمل لازك مانعي نداره؟(sim = 0.5641)\n",
            "\n",
            " #################################################################################################### [100.00%]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}